<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2.3 Deepfake Technology: The Science, Ethics, and Detection of Synthetic Media - Thorium-AI</title>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>
<body>
    <!-- Header will be loaded here -->
    <div id="header-container"></div>

    <main class="main-content">
        <article class="article-content">
            <header class="article-header">
                <h1 class="article-title">2.3 Deepfake Technology: The Science Behind Digital Deception</h1>
                <div class="article-meta">
                    <span><i class="fas fa-book"></i> Section 2: ChatGPT and Neural Networks</span>
                    <span><i class="fas fa-clock"></i> Reading time: 25 minutes</span>
                    <span><i class="fas fa-user"></i> By Thorium-AI Team</span>
                </div>
            </header>

            <div class="reading-section">
                <p>Imagine watching a seemingly authentic video of a world leader declaring war, a CEO announcing bankruptcy, or a family member pleading for emergency funds—except none of it ever happened. Welcome to the era of deepfakes, where artificial intelligence has shattered the centuries-old principle that "seeing is believing." Deepfake technology represents one of the most profound challenges to truth and trust in human history, powered by the same neural networks that create AI art and converse naturally. This article will take you deep into the technical workings, societal impacts, and detection methods of synthetic media.</p>

                <h2>The Technical Foundations: How Deepfakes Actually Work</h2>

                <p>At its core, deepfake technology is about learning and replicating human appearance and behavior through deep neural networks. Unlike simple video editing, deepfakes involve sophisticated AI models that understand facial geometry, expressions, lighting, and even subconscious micro-expressions.</p>

                <div class="note">
                    <p><strong>Core Technical Concept:</strong> Deepfakes operate by training neural networks to understand the complex mapping between facial expressions and underlying muscle movements, then applying this understanding to manipulate or generate new facial performances. The most advanced systems can now synthesize not just faces but entire bodies, gestures, and environmental interactions with alarming realism.</p>
                </div>

                <h3>Generative Adversarial Networks (GANs): The AI Arms Race</h3>

                <p>The most common architecture for creating deepfakes is the Generative Adversarial Network, a brilliant but dangerous innovation where two neural networks compete in a digital arms race:</p>

                <table>
                    <tr>
                        <th>Network</th>
                        <th>Role</th>
                        <th>Learning Objective</th>
                        <th>Typical Architecture</th>
                    </tr>
                    <tr>
                        <td><strong>Generator (G)</strong></td>
                        <td>Creates synthetic media</td>
                        <td>Minimize discriminator accuracy</td>
                        <td>U-Net, Autoencoder, or Transformer</td>
                    </tr>
                    <tr>
                        <td><strong>Discriminator (D)</strong></td>
                        <td>Detects synthetic media</td>
                        <td>Maximize classification accuracy</td>
                        <td>Convolutional Neural Network (CNN)</td>
                    </tr>
                </table>

                <p>The training process follows this adversarial loop:</p>

                <ol>
                    <li><strong>Step 1:</strong> Generator creates a fake image/video</li>
                    <li><strong>Step 2:</strong> Discriminator evaluates it alongside real media</li>
                    <li><strong>Step 3:</strong> Both networks update based on success/failure</li>
                    <li><strong>Step 4:</strong> Process repeats thousands of times</li>
                    <li><strong>Step 5:</strong> Nash equilibrium reached where fakes are indistinguishable</li>
                </ol>

                <div class="highlight">
                    <p><strong>Mathematical Insight:</strong> The GAN training objective is a minimax game: min_G max_D [E(log D(x)) + E(log(1 - D(G(z))))] where x is real data, z is random noise, G generates fakes, and D discriminates real from fake. This elegant formulation creates the competitive dynamic that drives quality improvement.</p>
                </div>

                <h3>Autoencoder Architectures: The Face Swapping Foundation</h3>

                <p>Most consumer deepfake tools use autoencoder architectures, specifically:</p>

                <ul>
                    <li><strong>Encoder:</strong> Compresses input face to latent representation (bottleneck)</li>
                    <li><strong>Decoder:</strong> Reconstructs face from latent representation</li>
                    <li><strong>Shared Encoder/Different Decoders:</strong> Encode any face, decode as specific person</li>
                </ul>

                <p>The training process for face swapping involves:</p>

                <ol>
                    <li>Train encoder to extract facial features independent of identity</li>
                    <li>Train decoder A to reconstruct person A's face</li>
                    <li>Train decoder B to reconstruct person B's face</li>
                    <li>During inference: Encode person B's face, decode with person A's decoder</li>
                </ol>

                <h2>The Complete Deepfake Creation Pipeline</h2>

                <h3>Phase 1: Data Collection and Preparation</h3>

                <p>High-quality deepfakes require extensive, diverse training data:</p>

                <table>
                    <tr>
                        <th>Data Type</th>
                        <th>Requirements</th>
                        <th>Quantity Needed</th>
                        <th>Purpose</th>
                    </tr>
                    <tr>
                        <td><strong>Source Material (A)</strong></td>
                        <td>Target person, high quality, diverse expressions</td>
                        <td>500-5,000 images</td>
                        <td>Learn facial identity and expressions</td>
                    </tr>
                    <tr>
                        <td><strong>Destination Material (B)</strong></td>
                        <td>Base video with target head movements</td>
                        <td>5-30 minutes video</td>
                        <td>Provide motion and context</td>
                    </tr>
                    <tr>
                        <td><strong>Alignment Frames</strong></td>
                        <td>Face-cropped, aligned images</td>
                        <td>Thousands</td>
                        <td>Consistent feature detection</td>
                    </tr>
                    <tr>
                        <td><strong>Landmark Data</strong></td>
                        <td>68-point facial landmarks</td>
                        <td>Per frame</td>
                        <td>Guide face warping and blending</td>
                    </tr>
                </table>

                <h3>Phase 2: Face Detection and Alignment</h3>

                <p>Using models like MTCNN (Multi-task Cascaded CNN) or RetinaFace:</p>

                <ul>
                    <li>Detect face bounding boxes in every frame</li>
                    <li>Extract 68 facial landmarks (eyes, nose, mouth, jaw)</li>
                    <li>Apply similarity transformation to align faces</li>
                    <li>Crop to standardized size (typically 256×256 or 512×512)</li>
                </ul>

                <h3>Phase 3: Model Training</h3>

                <p>The neural network learns through:</p>

                <ul>
                    <li><strong>Identity Loss:</strong> Ensure swapped face looks like target person</li>
                    <li><strong>Reconstruction Loss:</strong> Ensure decoded face matches input</li>
                    <li><strong>Adversarial Loss:</strong> Ensure discriminator can't detect fake</li>
                    <li><strong>Perceptual Loss:</strong> Ensure facial features match at feature level</li>
                </ul>

                <p>Training typically requires 24-72 hours on a high-end GPU for good results.</p>

                <h3>Phase 4: Face Swapping and Blending</h3>

                <p>Critical technical challenges include:</p>

                <ul>
                    <li><strong>Poisson Blending:</strong> Seamlessly merge swapped face into destination</li>
                    <li><strong>Color Correction:</strong> Match skin tones and lighting conditions</li>
                    <li><strong>Expression Transfer:</strong> Map source expressions to target geometry</li>
                    <li><strong>Hair and Occlusion Handling:</strong> Deal with hair covering face, glasses, etc.</li>
                </ul>

                <div class="warning">
                    <p><strong>Technical Limitations:</strong> Despite advances, deepfakes still struggle with:
                    <ul>
                        <li><strong>Consistent Eye Reflections:</strong> Corneal reflections often don't match environment</li>
                        <li><strong>Physiological Plausibility:</strong> Breathing patterns, pulse in neck, subtle skin movements</li>
                        <li><strong>Emotional Consistency:</strong> Micro-expressions that contradict main expression</li>
                        <li><strong>Long-term Temporal Coherence:</strong> Maintaining identity across long sequences</li>
                        <li><strong>Audio-Visual Synchronization:</strong> Perfect lip sync with complex phonemes</li>
                    </ul>
                    These limitations form the basis of many detection methods.</p>
                </div>

                <h2>Advanced Deepfake Techniques</h2>

                <h3>1. Neural Rendering and 3D Face Models</h3>

                <p>Cutting-edge approaches use 3D Morphable Models (3DMM):</p>

                <ul>
                    <li>Create 3D face model from single image using PRNet or Deep3DFace</li>
                    <li>Manipulate face in 3D space (pose, expression, lighting)</li>
                    <li>Re-render to 2D with neural rendering (NeRF, GRAF)</li>
                    <li>Enables full head rotation and extreme expressions</li>
                </ul>

                <h3>2. Few-Shot and One-Shot Learning</h3>

                <p>Recent models like FaceShifter and SimSwap can:</p>

                <ul>
                    <li>Create convincing fakes from just 1-10 reference images</li>
                    <li>Use attention mechanisms to focus on identity-relevant features</li>
                    <li>Separate identity from attributes (pose, expression, lighting)</li>
                    <li>Enable real-time deepfakes on consumer hardware</li>
                </ul>

                <h3>3. Audio-Driven Facial Animation</h3>

                <p>Systems like Wav2Lip and MakeItTalk:</p>

                <ul>
                    <li>Directly generate mouth movements from audio waveform</li>
                    <li>Use phoneme-to-viseme mapping learned from video data</li>
                    <li>Incorporate prosody and emotion into facial expressions</li>
                    <li>Enable realistic lip sync for any audio input</li>
                </ul>

                <h2>The Deepfake Detection Arms Race</h2>

                <p>As creation improves, so does detection—a classic technological arms race:</p>

                <h3>Technical Detection Methods</h3>

                <table>
                    <tr>
                        <th>Detection Method</th>
                        <th>Technical Basis</th>
                        <th>Effectiveness</th>
                        <th>Limitations</th>
                    </tr>
                    <tr>
                        <td><strong>Biological Signals</strong></td>
                        <td>Heart rate from facial blood flow, breathing patterns</td>
                        <td>High for video</td>
                        <td>Requires high framerate, affected by compression</td>
                    </tr>
                    <tr>
                        <td><strong>Blinking Analysis</strong></td>
                        <td>Natural blink patterns vs. synthetic</td>
                        <td>Medium</td>
                        <td>Easily faked with better training data</td>
                    </tr>
                    <tr>
                        <td><strong>Lighting Consistency</strong></td>
                        <td>3D lighting estimation from face reflections</td>
                        <td>High</td>
                        <td>Complex scenes, multiple light sources</td>
                    </tr>
                    <tr>
                        <td><strong>Digital Forensics</strong></td>
                        <td>Compression artifacts, camera sensor noise</td>
                        <td>High for low-quality</td>
                        <td>Fails with high-quality generation</td>
                    </tr>
                    <tr>
                        <td><strong>Facial Warping Artifacts</strong></td>
                        <td>Inconsistencies in facial geometry transformations</td>
                        <td>Medium-High</td>
                        <td>Improving with better warping algorithms</td>
                    </tr>
                    <tr>
                        <td><strong>Deep Learning Detectors</strong></td>
                        <td>CNN/Transformer models trained on real/fake datasets</td>
                        <td>Highest currently</td>
                        <td>Adversarial attacks, generalization issues</td>
                    </tr>
                </table>

                <h3>The Role of Deepfake Detection Datasets</h3>

                <p>Critical to detection research are comprehensive datasets:</p>

                <ul>
                    <li><strong>FaceForensics++:</strong> 1,000 videos with four manipulation methods</li>
                    <li><strong>DFDC (Facebook):</strong> 100,000+ videos with diverse deepfakes</li>
                    <li><strong>Celeb-DF:</strong> High-quality deepfakes of celebrities</li>
                    <li><strong>WildDeepfake:</strong> Real-world deepfakes collected from internet</li>
                    <li><strong>KoDF:</strong> Korean Deepfake Detection Dataset for demographic diversity</li>
                </ul>

                <div class="highlight">
                    <p><strong>Detection Challenge:</strong> The best current detectors achieve 85-95% accuracy on controlled datasets but drop to 60-75% on real-world examples. This performance gap represents the "generalization problem"—models trained on known manipulation techniques struggle with novel methods.</p>
                </div>

                <h2>Societal Impact and Real-World Cases</h2>

                <h3>Political and Geopolitical Implications</h3>

                <p>Documented cases include:</p>

                <ul>
                    <li><strong>Gabon Coup Attempt (2019):</strong> Deepfake video of president allegedly used to justify coup</li>
                    <li><strong>Ukrainian President Deepfake (2022):</strong> Fake surrender announcement during war</li>
                    <li><strong>Myanmar Military Use (2021):</strong> Alleged use of deepfakes for propaganda</li>
                    <li><strong>Election Interference:</strong> Multiple cases of fake candidate statements</li>
                </ul>

                <h3>Financial Fraud and Scams</h3>

                <p>Emerging threat vectors:</p>

                <ul>
                    <li><strong>CEO Fraud:</strong> Deepfake video/audio instructions for wire transfers</li>
                    <li><strong>Investment Scams:</strong> Fake endorsements from financial experts</li>
                    <li><strong>Crypto Scams:</strong> Fake Elon Musk videos promoting cryptocurrency schemes</li>
                    <li><strong>Blackmail:</strong> Threatening to release compromising deepfakes</li>
                </ul>

                <h3>Entertainment Industry Transformation</h3>

                <p>Positive applications include:</p>

                <ul>
                    <li><strong>Digital De-aging:</strong> The Irishman (Robert De Niro, Al Pacino)</li>
                    <li><strong>Posthumous Performances:</strong> Star Wars (Princess Leia, Grand Moff Tarkin)</li>
                    <li><strong>Language Localization:</strong> David Beckham malaria campaign in 9 languages</li>
                    <li><strong>Stunt Replacement:</strong> Safer stunt performances with actor's face</li>
                </ul>

                <h2>Legal and Regulatory Landscape</h2>

                <h3>Current Legislative Approaches</h3>

                <table>
                    <tr>
                        <th>Jurisdiction</th>
                        <th>Key Legislation</th>
                        <th>Focus</th>
                        <th>Penalties</th>
                    </tr>
                    <tr>
                        <td><strong>United States</strong></td>
                        <td>DEEPFAKES Accountability Act, state laws</td>
                        <td>Non-consensual porn, election interference</td>
                        <td>Fines, imprisonment (varies by state)</td>
                    </tr>
                    <tr>
                        <td><strong>European Union</strong></td>
                        <td>Digital Services Act, AI Act</td>
                        <td>Platform accountability, transparency</td>
                        <td>Fines up to 6% global revenue</td>
                    </tr>
                    <tr>
                        <td><strong>China</strong></td>
                        <td>Deep Synthesis Management Provisions</td>
                        <td>Content labeling, real-name registration</td>
                        <td>Service suspension, criminal liability</td>
                    </tr>
                    <tr>
                        <td><strong>South Korea</strong></td>
                        <td>Information and Communications Network Act</td>
                        <td>Malicious deepfake distribution</td>
                        <td>Up to 5 years imprisonment</td>
                    </tr>
                </table>

                <h3>Technical Solutions: Content Provenance</h3>

                <p>Emerging standards for authentication:</p>

                <ul>
                    <li><strong>C2PA (Coalition for Content Provenance and Authenticity):</strong> Adobe, Microsoft, BBC initiative</li>
                    <li><strong>Blockchain Timestamping:</strong> Immutable records of content origin</li>
                    <li><strong>Camera Fingerprinting:</strong> Sensor noise patterns as digital fingerprints</li>
                    <li><strong>Watermarking:</strong> Imperceptible markers in pixels or frequency domain</li>
                </ul>

                <h2>Practical Guide: How to Detect Deepfakes</h2>

                <h3>For Technical Analysts</h3>

                <ol>
                    <li><strong>Forensic Toolkits:</strong> Use tools like Amber Authenticate, Truepic, or Microsoft Video Authenticator</li>
                    <li><strong>Metadata Analysis:</strong> Check EXIF data, editing history, compression artifacts</li>
                    <li><strong>Frequency Domain Analysis:</strong> Look for inconsistencies in Fourier transforms</li>
                    <li><strong>Face Warping Analysis:</strong> Use OpenFace or Dlib for landmark consistency checks</li>
                </ol>

                <h3>For General Public</h3>

                <div class="tip">
                    <p><strong>The S.T.O.P. Framework:</strong><br>
                    <strong>S - Source:</strong> Where did this come from? Official channel or random account?<br>
                    <strong>T - Timing:</strong> When was this created? Does timeline match events?<br>
                    <strong>O - Originality:</strong> Can this be found elsewhere? Reverse image/video search<br>
                    <strong>P - Plausibility:</strong> Does this make sense? Context, behavior, circumstances</p>
                </div>

                <h2>The Future of Synthetic Media</h2>

                <h3>Near-Term Developments (1-3 years)</h3>

                <ul>
                    <li><strong>Real-time Deepfakes:</strong> Live video manipulation during video calls</li>
                    <li><strong>Fewer Data Requirements:</strong> Convincing fakes from single image</li>
                    <li><strong>Full Body Synthesis:</strong> Complete person generation with consistent motion</li>
                    <li><strong>Emotional Contagion:</strong> AI that understands and replicates emotional states</li>
                </ul>

                <h3>Long-Term Implications (5-10 years)</h3>

                <ul>
                    <li><strong>Personalized Media:</strong> News anchors that look like you, speaking your language</li>
                    <li><strong>Historical Recreation:</strong> Interactive experiences with historical figures</li>
                    <li><strong>Therapeutic Applications:</strong> Conversations with departed loved ones</li>
                    <li><strong>Identity Verification Crisis:</strong> Complete breakdown of visual identity verification</li>
                </ul>

                <div class="warning">
                    <p><strong>Existential Risk:</strong> The most concerning scenario is the "Liar's Dividend"—when real evidence can be dismissed as deepfake. This creates a world where truth becomes entirely subjective, undermining legal systems, journalism, and social trust. Political leaders could deny authentic recordings by claiming they're deepfakes.</p>
                </div>

                <h2>Ethical Framework for Responsible Development</h2>

                <p>Proposed principles for ethical synthetic media:</p>

                <ol>
                    <li><strong>Consent First:</strong> Never use someone's likeness without explicit permission</li>
                    <li><strong>Transparency Mandate:</strong> Clearly label all synthetic content</li>
                    <li><strong>Purpose Limitation:</strong> Restrict use to beneficial applications</li>
                    <li><strong>Accountability:</strong> Developers responsible for misuse prevention</li>
                    <li><strong>Sunset Provisions:</strong> Automatic expiration for certain uses</li>
                    <li><strong>Public Benefit:</strong> Prioritize applications that serve society</li>
                </ol>

                <h2>Protecting Yourself and Your Organization</h2>

                <h3>For Individuals</h3>

                <ul>
                    <li><strong>Digital Hygiene:</strong> Limit publicly available photos/videos</li>
                    <li><strong>Multi-factor Authentication:</strong> Especially for sensitive accounts</li>
                    <li><strong>Verification Protocols:</strong> Establish code words with family for emergencies</li>
                    <li><strong>Media Literacy Education:</strong> Regular training on detection techniques</li>
                </ul>

                <h3>For Organizations</h3>

                <ul>
                    <li><strong>Deepfake Response Plans:</strong> Pre-established protocols for incidents</li>
                    <li><strong>Employee Training:</strong> Regular updates on threat vectors</li>
                    <li><strong>Technical Safeguards:</strong> Implement C2PA or similar provenance standards</li>
                    <li><strong>Legal Preparedness:</strong> Relationships with digital forensics experts</li>
                </ul>

                <div class="tip">
                    <p><strong>Critical Thinking Exercise:</strong> Analyze a suspected deepfake by asking: What would it take to create this? Who benefits from its creation? What evidence contradicts it? How does it compare to known authentic examples? This systematic approach develops the skepticism needed in the synthetic media age.</p>
                </div>

                <h2>Conclusion: Navigating the New Reality</h2>

                <p>Deepfake technology represents a fundamental shift in human communication—the decoupling of representation from reality. Like the invention of writing, photography, and the internet before it, this technology will reshape society in ways we can only begin to imagine. The challenge is not to prevent its development (an impossible task) but to guide its evolution toward beneficial ends while mitigating harms.</p>

                <p>The most important defense against malicious deepfakes may not be technological but educational. Just as we teach children to read, we must now teach digital literacy that includes synthetic media awareness. The goal should be a society that can appreciate the creative potential of this technology while maintaining the critical thinking skills to distinguish truth from deception.</p>

                <p>In our next article, we'll explore voice cloning technology—the audio counterpart to deepfakes that presents equally significant challenges for security, privacy, and trust in the digital age.</p>

                <div class="highlight">
                    <p><strong>Final Perspective:</strong> Deepfake technology forces us to confront uncomfortable questions about truth, identity, and reality itself. In doing so, it may ultimately lead us to value authentic human connection more deeply and develop more sophisticated ways of establishing trust. The technology that threatens to deceive us may paradoxically teach us to be more discerning, more critical, and more appreciative of genuine human presence.</p>
                </div>
            </div>

            <!-- Navigation between articles -->
            <div class="article-navigation">
                <a href="2-2.html" class="nav-link">
                    <i class="fas fa-arrow-left"></i> Previous: 2.2 Midjourney/Stable Diffusion
                </a>
                <a href="2-4.html" class="nav-link">
                    Next: 2.4 Voice Cloning <i class="fas fa-arrow-right"></i>
                </a>
            </div>

            <!-- Tags for categorization -->
            <div class="article-tags">
                <span class="tag">Deepfake</span>
                <span class="tag">Synthetic Media</span>
                <span class="tag">Generative Adversarial Networks</span>
                <span class="tag">Face Swapping</span>
                <span class="tag">Digital Forensics</span>
                <span class="tag">Media Manipulation</span>
                <span class="tag">AI Ethics</span>
                <span class="tag">Misinformation</span>
                <span class="tag">Content Authentication</span>
                <span class="tag">Neural Rendering</span>
                <span class="tag">3D Face Models</span>
                <span class="tag">Detection Algorithms</span>
                <span class="tag">Digital Literacy</span>
                <span class="tag">Legal Regulation</span>
            </div>
        </article>
    </main>

    <script>
        // Load header
        fetch('header.html')
            .then(response => {
                if (!response.ok) throw new Error('Network response was not ok');
                return response.text();
            })
            .then(data => {
                document.getElementById('header-container').innerHTML = data;

                // Initialize mobile menu
                setupMobileMenu();

                // Highlight current article in navigation
                highlightCurrentArticle();
            })
            .catch(error => {
                console.error('Error loading header:', error);
                document.getElementById('header-container').innerHTML = `
                    <div style="padding: 20px; text-align: center; color: #666;">
                        <p>Error loading navigation. Please refresh the page.</p>
                        <p>If the problem persists, please check if header.html exists in the same directory.</p>
                    </div>
                `;
            });

        function setupMobileMenu() {
            const mobileMenuToggle = document.getElementById('mobileMenuToggle');
            const sidebar = document.getElementById('sidebar');
            const overlay = document.getElementById('overlay');

            if (!mobileMenuToggle || !sidebar || !overlay) {
                console.warn('Mobile menu elements not found.');
                return;
            }

            mobileMenuToggle.addEventListener('click', () => {
                sidebar.classList.toggle('active');
                overlay.classList.toggle('active');
                document.body.classList.toggle('mobile-menu-open');
            });

            overlay.addEventListener('click', () => {
                sidebar.classList.remove('active');
                overlay.classList.remove('active');
                document.body.classList.remove('mobile-menu-open');
            });

            // Accordion functionality for section titles
            document.querySelectorAll('.section-title').forEach(title => {
                title.addEventListener('click', () => {
                    title.classList.toggle('active');
                });
            });

            // Close menu when clicking on links (mobile)
            document.querySelectorAll('.topic-link').forEach(link => {
                link.addEventListener('click', () => {
                    if (window.innerWidth <= 768) {
                        sidebar.classList.remove('active');
                        overlay.classList.remove('active');
                        document.body.classList.remove('mobile-menu-open');
                    }
                });
            });

            // Close menu on Escape key
            document.addEventListener('keydown', (e) => {
                if (e.key === 'Escape') {
                    sidebar.classList.remove('active');
                    overlay.classList.remove('active');
                    document.body.classList.remove('mobile-menu-open');
                }
            });

            // Auto-close menu on desktop
            window.addEventListener('resize', () => {
                if (window.innerWidth > 768) {
                    sidebar.classList.remove('active');
                    overlay.classList.remove('active');
                    document.body.classList.remove('mobile-menu-open');
                }
            });
        }

        function highlightCurrentArticle() {
            const currentPath = window.location.pathname;
            const articleLinks = document.querySelectorAll('.topic-link');

            articleLinks.forEach(link => {
                if (link.getAttribute('href') === currentPath ||
                    link.getAttribute('href') === currentPath.replace('/thorium-ai/', '')) {
                    link.classList.add('active');

                    // Open the parent section
                    const parentSection = link.closest('.topic-list');
                    if (parentSection) {
                        const sectionTitle = parentSection.previousElementSibling;
                        if (sectionTitle && sectionTitle.classList.contains('section-title')) {
                            sectionTitle.classList.add('active');
                        }
                    }
                }
            });
        }

        // Auto-open the second section for this article
        document.addEventListener('DOMContentLoaded', () => {
            const secondSection = document.querySelector('[data-section="2"]');
            if (secondSection) {
                secondSection.classList.add('active');
            }
        });
    </script>
</body>
</html>
